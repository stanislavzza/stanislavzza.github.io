<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="David Eubanks">

<title>Chapter 2: The t-a-p Model – The Kappa Zoo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-f3c2ea88cadbcfb37ba28ffa2c97cfc1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-XP6WMESY52"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-XP6WMESY52', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">The Kappa Zoo</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul class="collapse">
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-conditional" id="toc-sec-conditional" class="nav-link" data-scroll-target="#sec-conditional"><span class="header-section-number">2</span> Conditional Probabilities</a></li>
  <li><a href="#sec-mixtures" id="toc-sec-mixtures" class="nav-link" data-scroll-target="#sec-mixtures"><span class="header-section-number">3</span> Binomial Mixtures</a></li>
  <li><a href="#sec-sims" id="toc-sec-sims" class="nav-link" data-scroll-target="#sec-sims"><span class="header-section-number">4</span> Simulation</a></li>
  <li><a href="#sec-fitting" id="toc-sec-fitting" class="nav-link" data-scroll-target="#sec-fitting"><span class="header-section-number">5</span> Fitting the Model</a></li>
  <li><a href="#sec-exact" id="toc-sec-exact" class="nav-link" data-scroll-target="#sec-exact"><span class="header-section-number">6</span> Exact Formulas for Accuracy</a></li>
  <li><a href="#sec-identifiability" id="toc-sec-identifiability" class="nav-link" data-scroll-target="#sec-identifiability"><span class="header-section-number">7</span> Identifiability</a></li>
  <li><a href="#sec-dk" id="toc-sec-dk" class="nav-link" data-scroll-target="#sec-dk"><span class="header-section-number">8</span> The Dunning-Kruger Horizon</a></li>
  <li><a href="#sec-overdispersion" id="toc-sec-overdispersion" class="nav-link" data-scroll-target="#sec-overdispersion"><span class="header-section-number">9</span> Overdispersion</a></li>
  <li><a href="#sec-other" id="toc-sec-other" class="nav-link" data-scroll-target="#sec-other"><span class="header-section-number">10</span> Other Properties</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 2: The t-a-p Model</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>David Eubanks </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<p>This chapter examines the assumptions and implications of the t-a-p model in detail to build a theoretical foundation for estimation and inference. This work also paves the way to connect the three parameter model to widely-used rater agreement statistics (kappas) and machine learning algorithms.</p>
<section id="sec-intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Suppose that we have <span class="math inline">\(N\)</span> subjects to be classified by at least two raters each, and each subject belongs (in truth) to one of two categories Class 1 or Class 0. For example, if faculty members review portfolios of student work, the two classes could be “pass” and “fail.” We often use ordered classifications like “A, B, C, D, F” or “Excellent, Good, Fair, Poor” but these can be converted to binary classifications by grouping the classes. For example “A, B, C” could be compared to “D, F” or “Excellent, Good” could be compared to “Fair, Poor.” There are also extensions of the t-a-p model that work directly on ordinal or non-binary categorical scales. The exposition is easiest to understand for the binary case, so we will start there.</p>
<p>We assume that each subject is independently assigned to one of the two classes by each of <span class="math inline">\(R\)</span> observers (raters). For now, think of <span class="math inline">\(R\)</span> as fixed, so that there are <span class="math inline">\(RN\)</span> total ratings, but that condition is relaxed later on, so that the number of ratings per subject can vary, which is common in real data.</p>
<p>Rater-assigned categories are distinguished from true classes in notation by the use of hats to suggest an estimated value. Ratings of Class 1 are denoted Class 1, but some of them may be Class 0 in truth. This distinction between rated (estimated) values and true values leads to the idea of true/false positives/negatives and the confusion matrix described in the introductory chapter, reproduced here.</p>
<div id="tbl-tap-confusion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-tap-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The t-a-p model’s correspondence to the confusion matrix. Terms in parentheses are inaccurate ratings.
</figcaption>
<div aria-describedby="tbl-tap-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 28%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>True C1</th>
<th>True C0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Classified C1</td>
<td><span class="math inline">\(ta + (t\bar{a}p)\)</span></td>
<td><span class="math inline">\((\bar{t}\bar{a}p)\)</span></td>
</tr>
<tr class="even">
<td>Classified C0</td>
<td><span class="math inline">\((t\bar{a}\bar{p})\)</span></td>
<td><span class="math inline">\(\bar{t}a + (\bar{t}\bar{a}\bar{p})\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The true positive rate of classification in <a href="#tbl-tap-confusion" class="quarto-xref">Table&nbsp;1</a> can be separated into ratings that are true for a good reason and those that are accidentally true. This chapter expands on that idea to reveal other properties of the t-a-p model and how some existing rater agreement statistics are special cases of it.</p>
<p>We will assume that an assigned rating corresponds to the <em>belief</em> of a rater. This rules out raters who are intentionally being deceptive, for example. Then we will say that a rater makes an <em>accurate</em> assignment of Class 1 or Class 0 for a subject if</p>
<ol type="1">
<li><p>the rater-assigned class is the true class, and</p></li>
<li><p>the rater has justification for the choice.</p></li>
</ol>
<p>These requirements operationalize the Justified True Belief (JTB) definition of knowledge used by philosophers who study epistemology. Inaccurate ratings are those where one of the two listed conditions fails. If the rater’s belief is false and chooses the wrong category or if they choose the correct category but because of an invalid justification. The latter case corresponds loosely to Gettier-type problems, where the chain of reasoning reaches a correct conclusion, but because of flaws in perception the logic isn’t sound. A clear case of failing the justification requirement is if raters flip coins to choose categories. Coin flipping is entirely random, but even good raters have some randomness inherent to the classifications. That randomness is the usual starting point for chance-corrected agreement statistics.</p>
<p>The rating process just described lends itself to a tree diagram that illustrates three variables as conditional probabilities: (1) the true Class 1 rate <span class="math inline">\(t\)</span>, (2) rater accuracy <span class="math inline">\(a\)</span>, and (3) the probability <span class="math inline">\(p\)</span> of choosing Class 1 when rating inaccurately. On the diagram, it’s convenient to use a bar over a variable to denote its complementary probability, e.g.&nbsp;<span class="math inline">\(\bar{a} = 1 - a\)</span>.</p>
<div id="fig-tree" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="t-a-p model diagram">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/avgtap.png" class="border img-fluid quarto-figure quarto-figure-center figure-img" alt="t-a-p model diagram">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Assumed rating process showing average rates, where <span class="math inline">\(c\)</span> is the rate of assigning Class 1 to subects, <span class="math inline">\(t\)</span> the average true Class 1 rate, and <span class="math inline">\(a\)</span> is average rater accuracy.
</figcaption>
</figure>
</div>
<p>Each rating is conditional on a subject’s true classification (Class 1 or Class 0), which will often be unknown, so that we can only observe the rater-assigned categories <span class="math inline">\(C_{ij}\)</span>, where <span class="math inline">\(i = 1 \dots N\)</span> are the subjects and <span class="math inline">\(j = 1 \dots R\)</span> are the raters, who independently classify subjects as Class 1 or Class 0. Define <span class="math inline">\(k_i := \sum_j C_{ij}\)</span> as the total number of ratings for subject <span class="math inline">\(i\)</span>, and the average of the classifications made by raters is <span class="math inline">\(c = \sum{C_{ij}}/(NR)\)</span>.</p>
<p>Example: A wine judge independently and honestly assesses a vintage for excellence. The two categories are Class 1 = “excellent” and Class 0 = “not excellent.” After judging four wines, the situation might be that in the table below.</p>
<table class="caption-top table">
<caption>Sample wine ratings showing normally unknown truth values.</caption>
<thead>
<tr class="header">
<th>Wine</th>
<th>Truth</th>
<th>Accurate?</th>
<th>Classification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Excellent</td>
<td>Yes</td>
<td>Excellent</td>
</tr>
<tr class="even">
<td>2</td>
<td>Excellent</td>
<td>No</td>
<td>Not Excellent</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Not Excellent</td>
<td>No</td>
<td>Not Excellent</td>
</tr>
<tr class="even">
<td>4</td>
<td>Not Excellent</td>
<td>Yes</td>
<td>Not Excellent</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Not Excellent</td>
<td>Yes</td>
<td>Not Excellent</td>
</tr>
</tbody>
</table>
<p>If the judge makes an accurate assessment, the classification recorded matches the true value. But for the third wine, the judge got the correct answer even though the process was flawed and somewhat random (an inaccurate rating). For the second wine, the inaccuracy resulted in the wrong classification being assigned. Those two inaccurate cases are illustrated in the process diagram in the middle, marked Random.</p>
</section>
<section id="sec-conditional" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Conditional Probabilities</h1>
<p>The tree diagram in figure <a href="#fig-tree" class="quarto-xref">Figure&nbsp;1</a> models the average assignments of ratings <span class="math inline">\(C_{ij}\)</span> over subject <span class="math inline">\(i\)</span> and rater <span class="math inline">\(j\)</span>, and can be read by multiplying the conditional probabilities on the edges from the top down to find the probability of a given classification being Class 1$.</p>
<p>If a subject is not classified accurately, the classification for that rater is assumed to be made at random, with probability <span class="math inline">\(p\)</span> of choosing Class 1 regardless of the true class. So the conditional probability of a Class 1 classification when the subject really is Class 1 is <span class="math inline">\(\text{Pr}(\text{Assigned Class 1} | \text{True Class 1}) = a + \bar{a}p\)</span>. Similarly, <span class="math inline">\(\text{Pr}(\text{Assigned Class 0} | \text{True Class 0}) = a + \bar{a}p\)</span>. This model assumes that guess rates for the two classes are the same independent of the true classification. More complex models are introduced later.</p>
<p>The binary (Bernoulli) probability that for a given subject with a given true classification, a rater will assign a Class 1 rating is shown in the table below. This comes from reading the tree diagram from the top down, multiplying the branches.</p>
<table class="caption-top table">
<caption>Conditional probabilities of a single rater assigning a Class 1 rating to a subject.</caption>
<thead>
<tr class="header">
<th></th>
<th>True C1</th>
<th>True C0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Classified C1</td>
<td><span class="math inline">\(a + \bar{a}p\)</span></td>
<td><span class="math inline">\(\bar{a}p\)</span></td>
</tr>
</tbody>
</table>
<p>We can use these probabilities to find the expected number of ratings of Class 1.</p>
</section>
<section id="sec-mixtures" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Binomial Mixtures</h1>
<p>The rating process posed in the t-a-p model is illustrated with the tree diagram and table of example ratings above. But both of those entail the use of the hidden true classification value for each subject. There are cases where that can be known, but in general it is not. What we usually have to work with is a table of ratings, from which we must infer the hidden variables like rater accuracy. The collection the ratings under the t-a-p assumptions fall into a well-studied probability distribution called a binomial mixture.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set the parameters</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>N_r <span class="ot">=</span> <span class="dv">5</span>    <span class="co"># number of raters for each subject </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>N_s <span class="ot">=</span> <span class="dv">100</span>  <span class="co"># number of subjects (not used here)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>t <span class="ot">=</span> .<span class="dv">3</span> <span class="co"># fraction of subjects that are in fact class 1</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> .<span class="dv">7</span> <span class="co"># probability of a rater rating a subject accurately</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> .<span class="dv">2</span> <span class="co"># probability of a rater rating a subject as class 1 when rating inaccurately</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># find the conditional probabilities for each class</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># probabilities of a class 1 rating for a class 0 subject</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  c0_probs <span class="ot">=</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span>N_r, N_r, <span class="at">prob =</span> (<span class="dv">1</span><span class="sc">-</span>a)<span class="sc">*</span>p)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># probabilities of a class 1 rating for a class 1 subject</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  c1_probs <span class="ot">=</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span>N_r, N_r, <span class="at">prob =</span> a <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>a)<span class="sc">*</span>p)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># create the mixture with t as the mixing parameter</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>mixture <span class="ot">=</span> c0_probs <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>t) <span class="sc">+</span> c1_probs <span class="sc">*</span> t</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the conditional probabilities</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>N_r, c0_probs, <span class="at">type=</span><span class="st">"b"</span>, <span class="at">col=</span><span class="st">"blue"</span>, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(<span class="fu">c</span>(c0_probs, c1_probs, mixture))),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Probability"</span>, <span class="at">xlab=</span><span class="st">"Number of class 1 ratings for a given subject"</span>, <span class="at">main=</span><span class="st">"Binomial Mixture Plot"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the second component (c1_probs)</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">0</span><span class="sc">:</span>N_r, c1_probs, <span class="at">type=</span><span class="st">"b"</span>, <span class="at">col=</span><span class="st">"red"</span>, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the mixture as a black dashed line</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="dv">0</span><span class="sc">:</span>N_r, mixture, <span class="at">type=</span><span class="st">"b"</span>, <span class="at">col=</span><span class="st">"black"</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Class 0 Probabilities"</span>, <span class="st">"Class 1 Probabilities"</span>, <span class="st">"Mixture"</span>),</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"black"</span>), <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>), <span class="at">pch=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-mixture" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mixture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tapmodel_files/figure-html/fig-mixture-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mixture-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Binomial mixture showing the probability of the number of class 1 ratings for a given subject. In blue is the distribution for true-class 0 subjects, in red is the distribution for true-class 1 subjects, and the black line is the mixture based on relative proportions.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-mixture" class="quarto-xref">Figure&nbsp;2</a> shows an example of how probabilities combine to create the mixture. Given the three t-a-p parameters plus the number of raters per subject, we apply the binomial probability density function using the probabilities found at the end of the previous section. The mixture is created by weighting these two distributions by their frequency in the sample space. In this case, the parameters are <span class="math inline">\(t = .3\)</span>, <span class="math inline">\(a = .7\)</span>, and <span class="math inline">\(p = .2\)</span>.</p>
<p>For true Class 1 cases, the probability of a rater assigning a Class 1 rating is <span class="math inline">\(ta + t\bar{a}p\)</span>, and for true Class 0 cases it is <span class="math inline">\(\bar{t}\bar{a}p\)</span> (see the table at the end of the last section). Those are probabilities for a single rating. If we have <span class="math inline">\(R\)</span> raters, then anywhere between zero and <span class="math inline">\(R\)</span> of them could assign a Class 1 rating to a given subject. The binomial distribution gives the probability for each of those possible count outcomes. For true Class 1 subjects the probability of <span class="math inline">\(k\)</span> raters assigning a Class 1 rating is</p>
<p><span class="math display">\[
\begin{aligned}
Pr(k | \text{True Class 1}) &amp;= \binom{R}{k} (a + \bar{a}p)^k (1 - a - \bar{a}p)^{R - k} \\
            &amp;= \binom{R}{k} (a + \bar{a}p)^k (\bar{a} - \bar{a}p)^{R - k} \\
            &amp;= \binom{R}{k} (a + \bar{a}p)^k (\bar{a} \bar{p})^{R - k}
\end{aligned}
\]</span></p>
<p>That distribution is represented by the red line in <a href="#fig-mixture" class="quarto-xref">Figure&nbsp;2</a>. Notice that the most outcome is that four of the five raters assign a Class 1 rating. The reason that’s not five is that the parameter <span class="math inline">\(p = .2\)</span> means that for inaccurate ratings, the “guess” is much more likely to assign Class 0 than Class 1. The effect is to deflate the number of Class 1 ratings for true Class 1 subjects.</p>
<p>For true Class 0 cases (the blue line in the plot), it is</p>
<p><span class="math display">\[ Pr(k | \text{True Class 0}) = \binom{R}{k} (\bar{a}p)^k (1 - \bar{a}p)^{R - k} \]</span></p>
<p>These are the two probability distributions are shown in <a href="#fig-mixture" class="quarto-xref">Figure&nbsp;2</a>, with the given parameters applied. The code is included so that you can try variations on your own.</p>
<p>But there are not necessarily the same number of true Class 1 and Class 0 cases. The fraction of Class 1 cases is assumed to be <span class="math inline">\(t\)</span>. The mixture of the two is</p>
<p><span id="eq-mixture-likelihood"><span class="math display">\[ Pr(k) = t \binom{R}{k} (a + \bar{a}p)^k (\bar{a}\bar{p})^{R - k} + \bar{t} \binom{R}{k} (\bar{a}p)^k (1 - \bar{a}p)^{R - k}.  \tag{1}\]</span></span></p>
<p>This is the mixture distribution that is assumed to represent the count data of Class 1 ratings per subject. To proceed with an investigation of the t-a-p model, we first count up the number of Class 1 ratings for each subject. If there are the same number of raters for each subject, these counts will form a histogram that corresponds to the black dashed line in the figure, for some set of t-a-p parameters. The job then is to find out what those parameters are.</p>
<p>For a real data set, the red and blue plots in <a href="#fig-mixture" class="quarto-xref">Figure&nbsp;2</a> are assumed to exist, but are not directly accessible to us. Instead we can see something like the mixture (black dashed line). But even that isn’t exact, because it is subject to sampling error: the histogram of counts won’t exactly correspond to the ideal probabilities. The larger the number of subjects rated, the closer the empirical proportions will, in theory, converge to the ideal mixture distribution.</p>
<p>For general information on binomial mixtures of discrete data see <span class="citation" data-cites="agresti2003categorical">Agresti (<a href="#ref-agresti2003categorical" role="doc-biblioref">2003</a>)</span> chapter 14.</p>
</section>
<section id="sec-sims" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Simulation</h1>
<p>The interactive app provided with the <code>tapModel</code> R package allows you to specify t-a-p parameters and generate a data set from them. Once the package is installed, you can run the app with <code>tapModel::launchApp().</code> Navigate to the Simulate Data tab.</p>
<div id="fig-sim-pair" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sim-pair-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/mixtures.png" class="border img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sim-pair-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Rating distributions with t = .3, a = .7, p = .2. Plot A has 20 subjects and Plot B has 1000. The blue bars are the histograms of the simulated data and the orange dashed line is the true mixture probability distribution.
</figcaption>
</figure>
</div>
<p><a href="#fig-sim-pair" class="quarto-xref">Figure&nbsp;3</a> shows two count histograms with identical parameters except for the number of subjects (20 versus 1000). The histograms are the result of applying the t-a-p binomial mixture distribution with five raters on each subject and parameter set <span class="math inline">\((t = .3, a = .7, p = .2)\)</span>. Notice that the smaller sample size on the left (plot A) doesn’t match the distribution line as well as the one on the right. This is the effect of random sampling. The smaller the sample, the more likely it is that the empirical counts don’t look like the distribution.</p>
<p>This leaves us with two problems: how do we estimate the parameters, and how much should we trust the results? These are classical problems from statistics.</p>
<p>The accuracy rate <span class="math inline">\(a\)</span> will affect the subject distributions. If <span class="math inline">\(a = 0\)</span> the ratings will be distributed as <span class="math inline">\(\text{Bernoulli}(p)\)</span>, independently of the subjects being rated. If <span class="math inline">\(a=1\)</span>, then all raters agree on the true value for each subject. Therefore the way we can reconstruct <span class="math inline">\(a\)</span> from data is through the distribution of the within-subject ratings. The method used here can be seen as a latent class model with binomial mixture distributions. For a nice discussion of these ideas in practice see <span class="citation" data-cites="grilli20155">Grilli et al. (<a href="#ref-grilli20155" role="doc-biblioref">2015</a>)</span>, which helpfully notes that binomial mixtures are statistically identifiable if the number of cases exceeds a low threshold <span class="citation" data-cites="mclachlan2000wiley">McLachlan &amp; Peel (<a href="#ref-mclachlan2000wiley" role="doc-biblioref">2000</a>)</span>.</p>
<p>We would like to know the true proportion <span class="math inline">\(t\)</span> of the subjects belonging to true Class 1 regardless of how they were rated, rater accuracy <span class="math inline">\(a\)</span>, and the proportion <span class="math inline">\(p\)</span> of inaccurate assignments that are Class 1. That goal describes the general model illustrated in the following section.</p>
</section>
<section id="sec-fitting" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Fitting the Model</h1>
<p>The first question about the model illustrated in figure <a href="#fig-tree" class="quarto-xref">Figure&nbsp;1</a> is whether it is computationally useful. Using known parameter values for <span class="math inline">\(t, a, p\)</span> to generate simulated ratings, can we then recover the parameters from the data? The answer is yes, with some provisos. Given a data set <span class="math inline">\(c_{ij}\)</span>, we can fit a general model to estimate the three parameters <span class="math inline">\(t\)</span>, <span class="math inline">\(a\)</span>, and <span class="math inline">\(p\)</span> using maximum likelihood to fit a binomial mixture model. The log likelihood function for the binomial mixture described by figure <a href="#fig-tree" class="quarto-xref">Figure&nbsp;1</a> with <span class="math inline">\(N\)</span> subjects and <span class="math inline">\(R_i\)</span> raters for subject <span class="math inline">\(i\)</span> is</p>
<p><span id="eq-efficient-likelihood"><span class="math display">\[
\begin{aligned}
\ell(t,a,p;R_1, \dots, R_N, k_1, \dots,k_N) &amp;= \sum_{i = 1}^N \log \left( t\binom{R_i}{k_i}(a + \bar{a}p)^{k_i}(\bar{a}\bar{p})^{R_i-k_i} +  \bar{t}\binom{R_i}{k_i}(\bar{a}p)^{k_i}(1-\bar{a}p)^{R_i-k_i} \right)  \\
&amp;= \sum_{i = 1}^N \log \left( t\,\text{binom}(R_i,k_i,a + \bar{a}p) +  \bar{t}\,\text{binom}(R_i,k_i,\bar{a}p) \right)  \\
&amp;= \sum_{u = 1}^{\text{unique}(R_i,k_i)}n_u \left[ \log \left( t\,\text{binom}(R_u,k_u,a + \bar{a}p) +  \bar{t}\,\text{binom}(R_u,k_u,\bar{a}p) \right)  \right]\\
\end{aligned}
\tag{2}\]</span></span></p>
<p>where <span class="math inline">\(k_i=\sum_{j}C_{ij}\)</span> is the number of Class 1 ratings for subject <span class="math inline">\(i\)</span>. The sum over the logs is justified by the assumption that ratings are independent (i.e.&nbsp;multiplying probabilities). The <span class="math inline">\(t\)</span> and <span class="math inline">\(\bar{t}\)</span> terms at the top of <a href="#eq-efficient-likelihood" class="quarto-xref">Equation&nbsp;2</a> are the mixing proportions for the two classes.</p>
<p>The second equation in <a href="#eq-efficient-likelihood" class="quarto-xref">Equation&nbsp;2</a> just rewrites the log-likelihood function more compactly to see the binomial mixture structure. The last equation is a more efficient way to calculate the likelihood, based on the observation that there are a limited number of pairs <span class="math inline">\((R_i,k_i)\)</span> that can occur in the data. For example, if there are three raters for each subject, then the possible pairs are <span class="math inline">\((4,0), (4,1), \dots, (4,4)\)</span>, five unique combinations regardless of the number of subjects <span class="math inline">\(N\)</span>. The likelihood is a sum over the unique pairs, multiplying each log-likelihood for that pair by the number of times it occurs in the data, denoted here by <span class="math inline">\(n_u\)</span>. In other words, the rating combination <span class="math inline">\((R_u, k_u)\)</span> occurs <span class="math inline">\(n_u\)</span> times. Using that formulation speeds up estimation algorithms because it reduces the number of calculations needed to fit the model.</p>
<p>It is straightforward to implement the function in the Bayesian programming language Stan <span class="citation" data-cites="carpenter2017stan">(<a href="#ref-carpenter2017stan" role="doc-biblioref">Carpenter et al., 2017</a>)</span>, using uniform <span class="math inline">\((0,1)\)</span> priors for the three parameters (see the discussion section at the end of that paper to access the source code).</p>
<p>To test the computational feasibility of this method, ratings were simulated using a range of values of <span class="math inline">\(t\)</span>, <span class="math inline">\(a\)</span>, and <span class="math inline">\(p\)</span>. The 729 trials each simulated 300 subjects with five raters each, using all combinations of values ranging from .1 to .9 in increments of .1 for each of <span class="math inline">\(t\)</span>, <span class="math inline">\(a\)</span>, and <span class="math inline">\(p\)</span>. The Stan engine uses a Markov chain Monte Carlo (MCMC) algorithm to gather representative samples from the joint probability density of the three parameters. Each run used 1,000 iterations (800 after warm-up) with four chains each.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-tap-sim" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tap-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tapmodel_files/figure-html/fig-tap-sim-1.png" class="img-fluid figure-img" width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tap-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Box and whisker plots show parameter estimates from simulations of rater data <span class="math inline">\(t\)</span>-<span class="math inline">\(a\)</span>-<span class="math inline">\(p\)</span> values ranging from .1 to .9. The diagonal line marks perfect estimates.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The accuracy measure <span class="math inline">\(a\)</span> and the Class 1 “guess rate” <span class="math inline">\(p\)</span> are stable across scenarios in figure <a href="#fig-tap-sim" class="quarto-xref">Figure&nbsp;4</a>, but the estimated true fraction of Class 1 cases <span class="math inline">\(t\)</span> is sensitive to values of <span class="math inline">\(a\)</span> near zero. To see this, substitute <span class="math inline">\(a = 0\)</span> into the likelihood function to get</p>
<p><span class="math display">\[
\begin{aligned}
\ell(t,p;a = 0, k_1, \dots,k_N) &amp;= \sum_{i = 1}^N t\log \left( \binom{R}{k_i}p^{k_i}(\bar{p})^{R-k_i} \right)+ \bar{t}\log \left(\binom{R}{k_i}p^{k_i}(\bar{p})^{R-k_i} \right) \\
&amp;= \sum_{i = 1}^N \log \left( \binom{R}{k_i}p^{k_i}(1-p)^{R-k_i}  \right).
\end{aligned}
\]</span></p>
<p>Since the two terms at the top are the same, and we sum <span class="math inline">\(t + \bar{t} = 1\)</span>, the <span class="math inline">\(t\)</span> drops out of the formula. So <span class="math inline">\(t\)</span> is under-determined when <span class="math inline">\(a = 0\)</span>, and we should expect poor behavior as <span class="math inline">\(a\)</span> nears zero. This is intuitive: if the raters are only guessing, they should give us no information about the true Class 1 rate. If the data in figure <a href="#fig-tap-sim" class="quarto-xref">Figure&nbsp;4</a> are filtered to <span class="math inline">\(a &gt; .2\)</span> the estimates of <span class="math inline">\(t\)</span> greatly improve. Aside from extreme values of <span class="math inline">\(a\)</span> affecting the estimation of <span class="math inline">\(t\)</span>, a visual inspection of the scatter plots of the parameter estimates shows no correlations.</p>
<p>The estimates in <a href="#fig-tap-sim" class="quarto-xref">Figure&nbsp;4</a> are taken from averages of the posterior parameter distributions, which is convenient, but sometimes hides the uncertainty in the estimates because of the limited range of possible values on [0,1]. When making inferences from a real data set, it’s useful to look at the full posterior distributions of the parameters to see if they are multi-modal or have other complications.</p>
</section>
<section id="sec-exact" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Exact Formulas for Accuracy</h1>
<p>As we’ll see in <a href="./kappa.html">Chapter 3</a>, the Fliess Kappa illustrates a “closed form” for calculating accuracy in the case when <span class="math inline">\(t = p\)</span>. We can find exact formulas for other special cases, which is useful for theoretical purposes. Consider the two-rater case on <span class="math inline">\(N_s\)</span> subjects, where the number of cases where both raters assigned Class 0 is <span class="math inline">\(n_0\)</span>, the mixed-rating case is <span class="math inline">\(n_1\)</span>, and the count of cases with both Class 1 is <span class="math inline">\(N_2\)</span>. The log likelihood function is</p>
<p><span class="math display">\[
\begin{aligned}
\ell(t,a,p)
&amp;= n_0\log [t(\bar{a}\bar{p})^2+ \bar{t}(1-\bar{a}p)^2]\\
&amp;+ n_1\log 2[t\bar{a}\bar{p}(a+\bar{a}p)+ \bar{t}\bar{a}p(1-\bar{a}p)] \\
&amp;+ n_2\log [t(a+\bar{a}p)^2+ \bar{t}(\bar{a}p)^2].
\end{aligned}
\]</span> If we further assume that <span class="math inline">\(t = p = 1/2\)</span>, after some simplification we arrive at</p>
<p><span class="math display">\[
\begin{aligned}
\ell(t = 1/2,a,p = 1/2)
&amp;= n_0 (\log (1+a^2) - 2)\\
&amp;+ n_1\log(1 - a^2) - 1 \\
&amp;+ n_2 (\log (1 + a^2) - 2),
\end{aligned}
\]</span> where we assume that the base for the log is <span class="math inline">\(1/2\)</span> (motivation for that choice is found in <a href="./hierarchical.html">Chapter 5</a>). When the log likelihood is maximized, the derivative is assumed to be zero, so we differentiate with respect to <span class="math inline">\(a\)</span> and obtain</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\ell(a)}{\partial a}
&amp;=  2a \left( \frac{n_0 + n_2}{1+a^2} -\frac{n_1}{1-a^2} \right)
\end{aligned}.
\]</span> Clearly, <span class="math inline">\(a=0\)</span> is one solution. The other is</p>
<p><span id="eq-exact-a"><span class="math display">\[
\begin{aligned}
a &amp;= \sqrt{\frac{n_0 - n_1+ n_2 }{n_0 + n_1 + n_2}} \\
&amp;=  \sqrt{\eta_0 - \eta_1 + \eta_2} \, ,
\end{aligned}
\tag{3}\]</span></span></p>
<p>where <span class="math inline">\(\eta_i = n_i/N_r\)</span> is the proportion of cases with <span class="math inline">\(i\)</span> ratings of Class 1. If there are no mismatched ratings, then <span class="math inline">\(\eta_1=0\)</span>, and <span class="math inline">\(a = 1\)</span>. If <span class="math inline">\(\eta_1 = 1/2\)</span>, then the ratings look like coin flips, and <span class="math inline">\(a = 0\)</span>. The form of <a href="#eq-exact-a" class="quarto-xref">Equation&nbsp;3</a> represents <span class="math inline">\(a^2\)</span> as a linear combination of match rates and mismatch rates. In fact, for unbiased raters (<span class="math inline">\(t=p\)</span>) we can derive the coefficients <span class="math inline">\(\beta_k\)</span> so that</p>
<p><span id="eq-exact-a-general"><span class="math display">\[
\begin{aligned}
a^2 &amp;= \sum_{k=0}^R \beta_k\ \eta_k  \\
\beta_k &amp;= \frac{k^2}{R(R-1)t\bar{t}}+ 1 - \frac{R}{(R-1)\bar{t}}. \\
\end{aligned}
\tag{4}\]</span></span></p>
<p>The derivation of the formula for <span class="math inline">\(\beta_k\)</span> is found in the <a href="./correlation.html">Appendix</a>. The linear models for <span class="math inline">\(a^2\)</span> are useful as theoretical tools, e.g.&nbsp;sensitivity analysis, but shouldn’t be used for direct estimation of accuracy, since the <span class="math inline">\(t=p\)</span> coefficient has to be specified, and the computation is sensitive to violations of the unbiased rater assumption. The supporting R package contains a function <code>tapModel::exact_accuracy_coefs(N_r, tp)</code> that computes the <span class="math inline">\(\beta_k\)</span> coefficients.</p>
</section>
<section id="sec-identifiability" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Identifiability</h1>
<p>Binomial mixtures are not always identifiable, meaning that the data don’t contain enough information to uniquely determine the parameters. If we fit two binomial distributions to the data with complete flexibility, each will have a “success rate” for the underlying Bernoulli trial, which determines the distribution’s mean and variance. There is also a weight parameter that defines the mixture; that determines the heights of the respective histograms of the two binomials. A simple data set would comprise the counts of Class 1 ratings for each subject. If the raters have reasonably high accuracy, a histogram of ratings will have a peak on the right, where a large fraction of raters of true Class 1 ratings agree. The average might be that 75 of 100 raters, on average agree that it’s Class 1. For true Class 0 cases, the raters might have an average of 25 of 100 ratings of Class 1 (erroneous ratings). The <a href="./app.html">chapter on the interactive application</a> shows how to simulate such data. It looks like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tapmodel1.png" class="img-fluid figure-img"></p>
<figcaption>Sample ratings with 100 raters and 1000 subject, with high rating accuracy. It shows a clear separation of the two binomial distributions.</figcaption>
</figure>
</div>
<p>If we ask a generic optimization algorithm for the statistics to describe the two binomials, we can get two valid answers, e.g. distribution means of <span class="math inline">\(\mu_0 = 25\)</span> and <span class="math inline">\(\mu_1= 75\)</span> or <span class="math inline">\(\mu_0 = 75\)</span> and <span class="math inline">\(\mu_1 = 25\)</span>. This is called “label-swapping,” because the solution doesn’t care which of the classes is which. One <em>ad hoc</em> solution is to include a restriction that the success rate for one of the distributions is greater than the other, but this is computationally awkward. The t-a-p model avoids this problem because the accuracy <span class="math inline">\(a\)</span> is the non-negative difference between the means of the two binomials. In the example above, <span class="math inline">\(a = .5 = (75-25)/100\)</span>. Since <span class="math inline">\(a\)</span> is bounded by 0 and 1, the model is generally identifiable.</p>
<p>Non-identifiable cases do occur when one or more of the t-a-p parameters is zero or one. If <span class="math inline">\(a = 1\)</span>, it doesn’t matter what <span class="math inline">\(p\)</span> is, for example. This can also cause problems when a parameter is <em>close</em> to one or zero. For an example of that, see <a href="./paradox.html">Chapter 4: The Kappa Paradox</a>. These issues can be investigated using Bayesian MCMC estimation, which provides a full posterior distribution for the parameters. The distribution may be multi-modal if there are two competing solutions. This gives us a way to detect degenerate solutions and look for a different model if desired. These degenerate cases aside, the tap parameterization of the binomial mixture has an advantage over generic optimization.</p>
<p>We can add more parameters to the basic t-a-p model. For example, we might split accuracy into Class 1 accuracy and Class 0 accuracy, as is illustrated in Chapter 4. These additions can lead to multiple solutions, which can often be detected from the MCMC distributions of parameters. This topic needs more development.</p>
</section>
<section id="sec-dk" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> The Dunning-Kruger Horizon</h1>
<p>The Dunning–Kruger effect <span class="citation" data-cites="kruger1999unskilled">(<a href="#ref-kruger1999unskilled" role="doc-biblioref">Kruger &amp; Dunning, 1999</a>)</span> is the tendency of people with low ability in some domain to overestimate their own ability (ignorance creates meta-ignorance). It turns out to be a useful metaphor for what happens when we estimate rater accuracy, because low rater accuracy degrades estimates of accuracy. We can visualize this effect using the linear model derived above for for exactly calculating accuracy (<span class="math inline">\(a\)</span>) when <span class="math inline">\(p=t=1/2\)</span> for two raters. If we suppose that thirty subjects are being rated (<span class="math inline">\(N_s=30\)</span>), the t-a-p model assumes a binomial mixture distribution for the counts of Class 1 ratings across all subjects. In particular, if accuracy is zero (<span class="math inline">\(a=0\)</span>), the count <span class="math inline">\(n_1\)</span> of the number of subjects that have split ratings (one Class 1 and one Class 0) will be distributed as a simple binomial with mean <span class="math inline">\(15 = 30(.5)\)</span>. With zero accuracy, the raters are essentially flipping coins. The question is, given this coin-flipping distribution for the results of the ratings, what are the possible accuracy ratings that reflect those random samples? Since we have an exact formula for the accuracy, we can draw a picture.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>N_s <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>( <span class="at">n1 =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">`</span><span class="at">Pr[n1]</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">dbinom</span>(n1, N_s, .<span class="dv">5</span>),</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">a       =</span> <span class="fu">if_else</span>(n1<span class="sc">*</span><span class="dv">2</span> <span class="sc">&gt;=</span> N_s, <span class="dv">0</span>,  <span class="fu">sqrt</span>((N_s <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>n1)<span class="sc">/</span>N_s)))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df <span class="sc">|&gt;</span> </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(statistic, value, <span class="sc">-</span>n1) <span class="sc">|&gt;</span> </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> n1, <span class="at">y =</span> value, <span class="at">group =</span> statistic, <span class="at">color =</span> statistic)) <span class="sc">+</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(<span class="at">xmin =</span> <span class="dv">11</span>, <span class="at">xmax =</span> <span class="dv">19</span>, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> <span class="cn">Inf</span>, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">fill =</span> <span class="st">"#CCCCCC22"</span>, <span class="at">color =</span> <span class="st">"#CCCCCC22"</span>) <span class="sc">+</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of Class 1 ratings (n1)"</span>) <span class="sc">+</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-random-a" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-random-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tapmodel_files/figure-html/fig-random-a-1.png" class="img-fluid figure-img" width="480">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-random-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Illustrating the range of accuracy estimates from random (a = 0, p = .5) ratings of 30 subjects with two raters each. The key statistic is how many mixed ratings n1 (one of each class) are generated, and the blue line shows the probability of each n1 occuring. The shaded region captures 90% of the distribution. The red line shows the accuracy estimate resulting from the sample.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The plot in <a href="#fig-random-a" class="quarto-xref">Figure&nbsp;5</a> shows how bad our estimate of accuracy can be for random ratings. Half of the time the count of mixed ratings <span class="math inline">\(n_1\)</span> will be greater than the mean of 15, and we’ll get the correct estimate of <span class="math inline">\(a = 0\)</span>. The other half of the time, when the number of mismatched ratings is less than 15, the estimate for accuracy quickly increases. We can see from the plot that there’s a significant chance that the estimated <span class="math inline">\(a \ge .25\)</span>. At the left edge of the shaded area, where <span class="math inline">\(n_1 = 11\)</span>, there is a 5% chance of this outcome, and the resulting accuracy estimate is a little more than .5.</p>
<p>The t-a-p model is asymetrical with respect to accuracy. If the ratings are 100% accurate, we’ll get the correct answer of <span class="math inline">\(a = 1\)</span> every time. But when the accuracy is zero, we’ll get a significant overestimate of <span class="math inline">\(a\)</span> almost half the time. This effect produces a “zone of ignorance” in the following sense. If we can’t <em>a priori</em> rule out a very low accuracy, then as a precautionary measure we should entertain the idea that the ratings are purely random. Maybe something went wrong with the raters or coding or data transmission. Maybe the subject IDs got mixed up. If it’s possible that the ratings could be random, then we must condider how large an estimate of accuracy can be in that condition. That depends on the sample size and <span class="math inline">\(p\)</span>. Assuming <span class="math inline">\(p=.5\)</span> is not universally applicable, but it’s a reasonable reference point.</p>
<p>If we choose the 5% mark as the cutoff value, as in <a href="#fig-random-a" class="quarto-xref">Figure&nbsp;5</a>, then given the number of subjects and average number of ratings, we can simulate the largest (worst) <span class="math inline">\(a\)</span> that can occur in those conditions at that threshold. I’ll call the resulting value of <span class="math inline">\(a\)</span> the “DK horizon” as a nod to Dunning and Kruger. The analogy isn’t perfect, but the idea is that if accuracy (like expertise) is low enough, a reversal happens, where our estimates of the accuracy increase instead of decrease.</p>
<p>For the example here, the DK horizon is <span class="math inline">\(a = .5\)</span>, meaning with 30 subjects and 2 raters each, any result that has <span class="math inline">\(a \le .5\)</span> is highly suspect; we could be looking at the result of coin-flipping raters. The DK horizon is a veil of ignorance that prevents us from interpreting the t-a-p model coefficients when accuracy is too low. The horizon is affected by sample size, so we can do something like a power analysis to estimate where the DK horizon is.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>sampled_a <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/a_sim_exact.csv"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>sampled_a <span class="sc">|&gt;</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> a, <span class="at">y =</span> a_sim, <span class="at">group =</span> a)) <span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">x =</span> a, <span class="at">y =</span> a_sim, <span class="at">group =</span> <span class="dv">1</span>), <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">linewidth =</span> .<span class="dv">9</span>) <span class="sc">+</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(N_s <span class="sc">~</span> N_r)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-a-sim" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-a-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tapmodel_files/figure-html/fig-a-sim-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-a-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Box plots showing the maximum likelihood estimate for accuracy (a) from samples drawn from a tap model with parameters t = p = 1/2 and a as shown on the horizontal axis. The 2, 5, 10, and 25 column headers are the number of raters for each subject, and the row headers along the right side are the number of subjects rated by each rater. The blue line is the average accuracy for the sampled ratings.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As is usually the case, larger sample sizes reduce sampling error. With 300 subjects and 25 raters each (bottom right), there’s hardly any sampling error. But for small sample sizes, the sampling error noticiably increases as accuracy approaches zero. For the 2-rater, 3-subject case in the top left of <a href="#fig-a-sim" class="quarto-xref">Figure&nbsp;6</a>, when <span class="math inline">\(a &lt; .5\)</span>, the estimation error quickly becomes so bad as to make the estimation worthless. Intuitively, if we got an estimate of <span class="math inline">\(a = .3\)</span>, say, the best we can say is that probably the accuracy is somewhere between zero and one half. For the 5-rater, 30-subject case, this “zone of ignorance” is not as bad, with the DK horizon at about <span class="math inline">\(a =.25\)</span>. This is useful knowledge when interpreting parameter estimates from a small sample of ratings.</p>
</section>
<section id="sec-overdispersion" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Overdispersion</h1>
<p>The basic t-a-p model assumes fixed averages of the three parameters over raters and subjects. The most sensible of these assumptions is that there is a single value for <span class="math inline">\(t\)</span> that represents the fraction of Class 1 cases. That leaves two parameters that are certainly oversimplified in the tap model, so that counts of Class 1 ratings per subject are likely to have more variance than a binomial model would. This is due to anticipated variance in rater ability and the difficulty in rating subjects, resulting in <a href="https://en.wikipedia.org/wiki/Overdispersion">overdispersion</a>. A general approach to this problem is to allow each rater to have a different accuracy rate <span class="math inline">\(a_j\)</span> and each subject to have a different guessing rate <span class="math inline">\(p_i\)</span>. This is a hierarchical model, which is described in <a href="./hierarchical.html">Chapter 5: Hierarchical Models</a>. Other approaches include using a beta-binomial prior for parameters, <span class="citation" data-cites="williams1975394">Williams (<a href="#ref-williams1975394" role="doc-biblioref">1975</a>)</span>. Also see <span class="citation" data-cites="ascari2021new">Ascari &amp; Migliorati (<a href="#ref-ascari2021new" role="doc-biblioref">2021</a>)</span>.</p>
</section>
<section id="sec-other" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Other Properties</h1>
<p>As is shown in <a href="./correlation.html">Appendix A</a>, rater accuracy <span class="math inline">\(a\)</span> is proportional to the correlation between the true and assigned classifications. If <span class="math inline">\(C\)</span> is the true classification and <span class="math inline">\(T\)</span> is the assigned classification, then</p>
<p><span class="math display">\[ \text{Cor}(T, C) = a\frac{\sigma_T}{\sigma_C} \]</span></p>
<p>Related properties can be found in the appendix.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-agresti2003categorical" class="csl-entry" role="listitem">
Agresti, A. (2003). <em>Categorical data analysis</em> (Vol. 482). John Wiley &amp; Sons.
</div>
<div id="ref-ascari2021new" class="csl-entry" role="listitem">
Ascari, R., &amp; Migliorati, S. (2021). A new regression model for overdispersed binomial data accounting for outliers and an excess of zeros. <em>Statistics in Medicine</em>, <em>40</em>(17), 3895–3914.
</div>
<div id="ref-carpenter2017stan" class="csl-entry" role="listitem">
Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., &amp; Riddell, A. (2017). Stan: A probabilistic programming language. <em>Journal of Statistical Software</em>, <em>76</em>(1).
</div>
<div id="ref-grilli20155" class="csl-entry" role="listitem">
Grilli, L., Rampichini, C., &amp; Varriale, R. (2015). Binomial mixture modeling of university credits. <em>Communications in Statistics - Theory and Methods</em>, <em>44</em>(22), 4866–4879. <a href="https://doi.org/10.1080/03610926.2013.804565">https://doi.org/10.1080/03610926.2013.804565</a>
</div>
<div id="ref-kruger1999unskilled" class="csl-entry" role="listitem">
Kruger, J., &amp; Dunning, D. (1999). Unskilled and unaware of it: How difficulties in recognizing one’s own incompetence lead to inflated self-assessments. <em>Journal of Personality and Social Psychology</em>, <em>77</em>(6), 1121.
</div>
<div id="ref-mclachlan2000wiley" class="csl-entry" role="listitem">
McLachlan, G., &amp; Peel, D. (2000). Wiley series in probability and statistics. <em>Finite Mixture Models</em>, 420–427.
</div>
<div id="ref-williams1975394" class="csl-entry" role="listitem">
Williams, D. (1975). 394: The analysis of binary responses from toxicological experiments involving reproduction and teratogenicity. <em>Biometrics</em>, 949–952.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>